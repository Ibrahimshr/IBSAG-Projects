# -*- coding: utf-8 -*-
"""Fraud_Detection2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JqhzyrD3u_ofdZ05fpiMMDAsPyplADtW
"""

# Commented out IPython magic to ensure Python compatibility.
#Loading the packages of the 1906899_SWE6204_A2_code
import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline 
import plotly.graph_objs as go
import plotly.figure_factory as ff
from plotly import tools
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
init_notebook_mode(connected=True)

sns.set_style("whitegrid")

import gc
from datetime import datetime 
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
#Importing the algorithms
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn import svm
import lightgbm as lgb
from lightgbm import LGBMClassifier
import xgboost as xgb


#importing the datasets using the csv file of the 1906899_SWE6204_A2_code
data_df = pd.read_csv("creditcard.csv")
#getting the look of the data and how the data is presented of the 1906899_SWE6204_A2_code
data_df.head()

"""# New Section"""

#exploring the data of the 1906899_SWE6204_A2_code
data_df.info()

#looking into more details to the data of the 1906899_SWE6204_A2_code
pd.set_option("display.float", "{:.2f}".format)
data_df.describe()

#checking the missing values in the dataset of the 1906899_SWE6204_A2_code
data_df.isnull().sum().sum()

data_df.columns

#Transaction class distribution of the 1906899_SWE6204_A2_code
LABELS = ["Normal", "Fraud"]

count_classes = pd.value_counts(data_df['Class'], sort = True)
count_classes.plot(kind = 'bar', rot=0)
plt.title("Transaction Class Distribution")
plt.xticks(range(2), LABELS)
plt.xlabel("Class")
plt.ylabel("Frequency");

#checking the class distribution of the 1906899_SWE6204_A2_code
data_df.Class.value_counts()

#displaying the number of fraud and valid transactions in the entire dataset of the 1906899_SWE6204_A2_code
fraud = data_df[data_df['Class']==1]
normal = data_df[data_df['Class']==0]

print(f"Shape of Fraudulant transactions: {fraud.shape}")
print(f"Shape of Non-Fraudulant transactions: {normal.shape}")

#Functional display of the amount of money used in different transaction classes of the 1906899_SWE6204_A2_code
pd.concat([fraud.Amount.describe(), normal.Amount.describe()], axis=1)

#Fuctional display of transaction time of the 1906899_SWE6204_A2_code
pd.concat([fraud.Time.describe(), normal.Time.describe()], axis=1)

#Displaying the histogram of transaction of the time of the 1906899_SWE6204_A2_code
plt.figure(figsize=(14, 12))

plt.subplot(2, 2, 1)
data_df[data_df.Class == 1].Time.hist(bins=35, color='blue', alpha=0.6, label="Fraudulant Transaction")
plt.legend()

plt.subplot(2, 2, 2)
data_df[data_df.Class == 0].Time.hist(bins=35, color='blue', alpha=0.6, label="Non Fraudulant Transaction")
plt.legend()

#Data pre-processing spliting of the data for training it and validating it of the 1906899_SWE6204_A2_code 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

scalar = StandardScaler()

X = data_df.drop('Class', axis=1)
y = data_df.Class

X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, 
                                                    test_size=0.3, random_state=42)
X_train, X_validate, y_train, y_validate = train_test_split(X_train_v, y_train_v, 
                                                            test_size=0.2, random_state=42)

X_train = scalar.fit_transform(X_train)
X_validate = scalar.transform(X_validate)
X_test = scalar.transform(X_test)

w_p = y_train.value_counts()[0] / len(y_train)
w_n = y_train.value_counts()[1] / len(y_train)

print(f"Fraudulant transaction weight: {w_n}")
print(f"Non-Fraudulant transaction weight: {w_p}")

#traning, validating, and testing of data of the 1906899_SWE6204_A2_code
print(f"TRAINING: X_train: {X_train.shape}, y_train: {y_train.shape}\n{'_'*55}")
print(f"VALIDATION: X_validate: {X_validate.shape}, y_validate: {y_validate.shape}\n{'_'*50}")
print(f"TESTING: X_test: {X_test.shape}, y_test: {y_test.shape}")

#importing the accuracy score, confusion matrix, classification, f1 score of the data of the 1906899_SWE6204_A2_code
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score

def print_score(label, prediction, train=True):
    if train:
        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))
        print("Train Result of the algorithm:\n")
        print(f"Accuracy Score: {accuracy_score(label, prediction) * 100:.2f}%")
        print("________________________________________________________________")
        print(f"Classification Report:\n{clf_report}")
        print("________________________________________________________________")
        print(f"Confusion Matrix: \n {confusion_matrix(y_train, prediction)}\n")
        
    elif train==False:
        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))
        print("Test Result of the algorithm:\n")        
        print(f"Accuracy Score: {accuracy_score(label, prediction) * 100:.2f}%")
        print("_______________________________________________________________")
        print(f"Classification Report:\n{clf_report}")
        print("________________________________________________________________")
        print(f"Confusion Matrix: \n {confusion_matrix(label, prediction)}\n")

#model building using the algorithms  of the 1906899_SWE6204_A2_code
#XGBoost Algorithm
xgb_clf = XGBClassifier()
xgb_clf.fit(X_train, y_train, eval_metric='aucpr')

y_train_pred = xgb_clf.predict(X_train)
y_test_pred = xgb_clf.predict(X_test)

print_score(y_train, y_train_pred, train=True)
print_score(y_test, y_test_pred, train=False)

scores_dict = {
    'XGBoost': {
        'Train': f1_score(y_train, y_train_pred.round()),
        'Test': f1_score(y_test, y_test_pred.round()),
    },
}

#Random Forest Algorithm of 1906899_SWE6204_A2_code
rf_clf = RandomForestClassifier(n_estimators=100, oob_score=False)
rf_clf.fit(X_train, y_train)

y_train_pred = rf_clf.predict(X_train)
y_test_pred = rf_clf.predict(X_test)

print_score(y_train, y_train_pred, train=True)
print_score(y_test, y_test_pred, train=False)

scores_dict['Random Forest'] = {
        'Train': f1_score(y_train,y_train_pred),
        'Test': f1_score(y_test, y_test_pred),
}

#Lightgbm  Algorithm of 1906899_SWE6204_A2_code
lgbm_clf = LGBMClassifier()
lgbm_clf.fit(X_train, y_train)

y_train_pred = lgbm_clf.predict(X_train)
y_test_pred = lgbm_clf.predict(X_test)

print_score(y_train, y_train_pred, train=True)
print_score(y_test, y_test_pred, train=False)

scores_dict['LigthGBM'] = {
        'Train': f1_score(y_train,y_train_pred),
        'Test': f1_score(y_test, y_test_pred),
}

#Logistic Regression  Algorithm of 1906899_SWE6204_A2_code
lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)

y_train_pred = lr_clf.predict(X_train)
y_test_pred = lr_clf.predict(X_test)

print_score(y_train, y_train_pred, train=True)
print_score(y_test, y_test_pred, train=False)

scores_dict['Logistic Regression'] = {
        'Train': f1_score(y_train,y_train_pred),
        'Test': f1_score(y_test, y_test_pred),
}

#Comapring the algorithms basesd on the train and test data of 1906899_SWE6204_A2_code
scores_df = pd.DataFrame(scores_dict)

scores_df.plot(kind='barh', figsize=(15, 8))